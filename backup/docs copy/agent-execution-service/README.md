# Agent Execution Service

## DescripciÃ³n
Servicio encargado de la ejecuciÃ³n de agentes, procesamiento de solicitudes de los usuarios y coordinaciÃ³n con servicios de consulta y embedding.

## ğŸ—ï¸ Ecosistema de Servicios

La arquitectura se organiza en 3 niveles jerÃ¡rquicos:

### Nivel 1: OrquestaciÃ³n

- **Agent Orchestrator**: Punto de entrada Ãºnico, gestiÃ³n de sesiones y coordinaciÃ³n global

### Nivel 2: Servicios Funcionales

- **Conversation Service**: Historial y contexto de conversaciones
- **Workflow Engine**: Flujos de trabajo complejos multi-etapa
- **Agent Execution**: LÃ³gica especÃ­fica del agente
- **Tool Registry**: Registro y ejecuciÃ³n de herramientas

### Nivel 3: Servicios de Infraestructura

- **Query Service**: Procesamiento RAG y LLM
- **Embedding Service**: GeneraciÃ³n de embeddings vectoriales
- **Ingestion Service**: Procesamiento de documentos

> ğŸ“Œ **Este documento describe el Agent Execution Service**, ubicado en el Nivel 2 como servicio funcional encargado de la ejecuciÃ³n de la lÃ³gica especÃ­fica de cada agente

## ğŸ”„ Flujos de Trabajo Principales

### 1. Consulta Normal (ParticipaciÃ³n del Agent Execution)
```
Cliente â†’ Orchestrator â†’ Agent Execution â†’ Embedding Service â†’ Query Service â†’ Respuesta
```

### 2. EjecuciÃ³n con Herramientas
```
Cliente â†’ Orchestrator â†’ Agent Execution â†’ Tool Registry â†’ [EjecuciÃ³n de herramientas] â†’ Query Service â†’ Respuesta
```

> ğŸ” **Rol del Agent Execution**: Ejecutar la lÃ³gica principal del agente, coordinando interacciones con las herramientas, procesando prompts y manejando llamadas a LLM.

## Estructura
```
agent-execution-service/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py              # AgentExecutionSettings
â”‚   â””â”€â”€ constants.py             # Modelos LLM, timeouts
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ execution.py             # ExecutionRequest, ExecutionResponse
â”‚   â”œâ”€â”€ prompt.py                # PromptTemplate, PromptConfig
â”‚   â”œâ”€â”€ completion.py            # CompletionRequest, CompletionResponse
â”‚   â””â”€â”€ tool_call.py             # ToolCall, ToolResult
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ execute.py               # Endpoints de ejecuciÃ³n
â”‚   â”œâ”€â”€ internal.py              # APIs internas
â”‚   â””â”€â”€ health.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ langchain_executor.py    # LangChainExecutor principal
â”‚   â”œâ”€â”€ prompt_processor.py      # Procesamiento de prompts
â”‚   â”œâ”€â”€ tool_orchestrator.py     # OrquestaciÃ³n de herramientas
â”‚   â””â”€â”€ llm_factory.py           # Factory para modelos LLM
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ openai_provider.py       # Proveedor OpenAI
â”‚   â”œâ”€â”€ groq_provider.py         # Proveedor Groq
â”‚   â””â”€â”€ base_provider.py         # Interface base
â”œâ”€â”€ queue/                       # Sistema de cola de trabajo
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ consumer.py              # Consumidor de tareas
â”‚   â”œâ”€â”€ producer.py              # Productor de tareas
â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ execution_tasks.py    # Tareas de ejecuciÃ³n
â”‚       â””â”€â”€ batch_tasks.py        # Procesamiento por lotes
â”œâ”€â”€ websocket/                   # ComunicaciÃ³n en tiempo real
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ connection_manager.py    # GestiÃ³n de conexiones WebSocket
â”‚   â”œâ”€â”€ events.py                # DefiniciÃ³n de eventos
â”‚   â””â”€â”€ handlers.py              # Manejadores de eventos
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md

## ğŸš¦ Sistema de Colas Multi-tenant

### Estructura JerÃ¡rquica de Colas del Agent Execution Service

```
+--------------------------------------------------+
|             COLAS DE AGENT EXECUTION              |
+--------------------------------------------------+
|                                                  |
| agent_execution:{tenant_id}                      | â†’ Cola principal de tareas
| agent_tools:{tenant_id}:{agent_id}               | â†’ Llamadas a herramientas
| agent_responses:{tenant_id}:{execution_id}       | â†’ Respuestas de ejecuciÃ³n
| agent_streaming:{tenant_id}:{execution_id}       | â†’ Respuestas en streaming
|                                                  |
+--------------------------------------------------+
```

### CaracterÃ­sticas Clave

- **SegmentaciÃ³n por tenant**: Completo aislamiento de datos entre tenants
- **EjecuciÃ³n asÃ­ncrona**: Procesamiento no bloqueante de solicitudes
- **Retries inteligentes**: Manejo automÃ¡tico de fallos transitorios
- **Prioridades dinÃ¡micas**: Ajuste de prioridad segÃºn tipo de agente y plan

### Formato de Mensaje Estandarizado

```json
{
  "task_id": "uuid-v4",
  "tenant_id": "tenant-identifier",
  "agent_id": "agent-identifier",
  "execution_id": "execution-uuid",
  "created_at": "ISO-timestamp",
  "status": "pending|processing|completed|failed",
  "type": "agent_execution|tool_call|streaming_response",
  "priority": 0-9,
  "metadata": {
    "conversation_id": "conversation-id",
    "session_id": "session-identifier",
    "workflow_id": "optional-workflow-id",
    "source": "api|orchestrator|workflow"
  },
  "payload": {
    "query": "Consulta del usuario",
    "agent_config": {},
    "context": {},
    "tool_calls": []
  }
}
```

## ğŸ”Œ Sistema de Notificaciones

### WebSockets Centralizados

- **IntegraciÃ³n con orquestador**: ConexiÃ³n bidireccional con Agent Orchestrator
- **Modo streaming**: EnvÃ­o incremental de tokens de respuesta
- **Notificaciones de herramientas**: Eventos para llamadas a herramientas
- **ReconexiÃ³n automÃ¡tica**: Mecanismo de backoff exponencial para mayor resiliencia
- **AutenticaciÃ³n por token**: ComunicaciÃ³n segura entre servicios

### Eventos EspecÃ­ficos del Agent Execution Service

- `agent_execution_started`: Inicio de la ejecuciÃ³n del agente
- `tool_call_requested`: Solicitud de llamada a herramienta
- `agent_response_token`: Token individual en modo streaming
- `agent_execution_completed`: Respuesta completa generada
- `agent_execution_failed`: Error en la ejecuciÃ³n del agente

### ImplementaciÃ³n WebSocket para Notificaciones:

```python
# websocket/notifier.py
import asyncio
import websockets
import json
import logging
from datetime import datetime

ORCHESTRATOR_WS_URL = "ws://agent-orchestrator:8000/ws/task_updates"

logger = logging.getLogger(__name__)

async def notify_agent_progress(task_id, tenant_id, execution_data, global_task_id=None):
    """Notifica el progreso de una ejecuciÃ³n de agente"""
    try:
        async with websockets.connect(ORCHESTRATOR_WS_URL) as websocket:
            notification = {
                "event": "agent_execution_progress",
                "service": "agent-execution",
                "task_id": task_id,
                "global_task_id": global_task_id,
                "tenant_id": tenant_id,
                "timestamp": datetime.utcnow().isoformat(),
                "data": execution_data
            }
            await websocket.send(json.dumps(notification))
    except Exception as e:
        logger.error(f"Error al notificar progreso de agente via WebSocket: {e}")

async def stream_agent_token(task_id, tenant_id, token, is_final=False, global_task_id=None):
    """EnvÃ­a un token individual en modo streaming"""
    try:
        async with websockets.connect(ORCHESTRATOR_WS_URL) as websocket:
            notification = {
                "event": "agent_response_token",
                "service": "agent-execution",
                "task_id": task_id,
                "global_task_id": global_task_id,
                "tenant_id": tenant_id,
                "timestamp": datetime.utcnow().isoformat(),
                "data": {
                    "token": token,
                    "is_final": is_final
                }
            }
            await websocket.send(json.dumps(notification))
    except Exception as e:
        logger.error(f"Error al enviar token streaming: {e}")
```

## ğŸŒ IntegraciÃ³n en el Ecosistema

### Beneficios de la Arquitectura

- **EspecializaciÃ³n en ejecuciÃ³n**: Foco en la lÃ³gica del agente sin preocuparse por orquestaciÃ³n
- **IntegraciÃ³n flexible**: Soporte para mÃºltiples proveedores de LLM y formatos de prompt
- **SeparaciÃ³n de responsabilidades**: Clara divisiÃ³n entre ejecuciÃ³n y herramientas
- **Escalabilidad independiente**: Puede escalarse segÃºn la demanda de agentes activos
```

## Funciones Clave
1. EjecuciÃ³n de agentes con LLMs (Groq, OpenAI)
2. Procesamiento de prompts y completion
3. OrquestaciÃ³n de herramientas y llamadas a herramientas
4. Streaming de respuestas generativas

## Sistema de Cola de Trabajo
- **Tareas**: Procesamiento asÃ­ncrono de ejecuciones complejas, lotes de inferencias
- **ImplementaciÃ³n**: Redis Queue con prioridad para tareas crÃ­ticas
- **Procesamiento**: Tareas en segundo plano para ejecuciones que requieren mÃ¡s tiempo

## ComunicaciÃ³n
- **HTTP**: API REST para solicitudes de ejecuciÃ³n
- **WebSocket**: Streaming de respuestas y actualizaciones de ejecuciÃ³n
- **Callbacks**: Notificaciones de finalizaciÃ³n de tareas en cola

## IntegraciÃ³n con otros Servicios
El Agent Execution Service se comunica principalmente con:
1. Tool Registry Service: Para ejecutar herramientas durante el proceso de razonamiento
2. Agent Management Service: Para obtener configuraciones de agentes
3. Agent Orchestrator Service: Para solicitar operaciones de consulta o embedding (NO directamente con Query/Embedding Services)