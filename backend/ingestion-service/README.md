# Ingestion Service

## Descripci√≥n

Ingestion Service es un microservicio especializado responsable de todo el proceso de ingesta de documentos para el sistema RAG (Retrieval Augmented Generation). El servicio maneja la recepci√≥n, procesamiento, extracci√≥n de texto, chunking y orquestaci√≥n del almacenamiento de documentos y sus embeddings correspondientes.

## üèóÔ∏è Ecosistema de Servicios

La arquitectura se organiza en 3 niveles jer√°rquicos:

### Nivel 1: Orquestaci√≥n

- **Agent Orchestrator**: Punto de entrada √∫nico, gesti√≥n de sesiones y coordinaci√≥n global

### Nivel 2: Servicios Funcionales

- **Conversation Service**: Historial y contexto de conversaciones
- **Workflow Engine**: Flujos de trabajo complejos multi-etapa
- **Agent Execution**: L√≥gica espec√≠fica del agente
- **Tool Registry**: Registro y ejecuci√≥n de herramientas

### Nivel 3: Servicios de Infraestructura

- **Query Service**: Procesamiento RAG y LLM
- **Embedding Service**: Generaci√≥n de embeddings vectoriales
- **Ingestion Service**: Procesamiento de documentos

> üìå **Este documento describe el Ingestion Service**, ubicado en el Nivel 3 como servicio de infraestructura especializado en el procesamiento y preparaci√≥n de documentos para el sistema RAG

## Caracter√≠sticas

- Soporte para m√∫ltiples formatos de documentos (PDF, Word, Excel, texto, HTML, im√°genes, etc.)
- Procesamiento as√≠ncrono mediante sistema de colas
- Chunking inteligente optimizado para RAG
- Extracci√≥n de texto con reconocimiento de estructura
- Gesti√≥n de colecciones de documentos
- Ingesta desde m√∫ltiples fuentes (archivos, URLs, texto plano)
- Soporte para procesamiento por lotes
- Tracking centralizado de tokens y uso de recursos

## üîÑ Flujos de Trabajo Principales

### 1. Ingesti√≥n de Documentos (Flujo principal)
```
Cliente ‚Üí Orchestrator ‚Üí Workflow Engine ‚Üí Ingestion Service ‚Üí Embedding Service ‚Üí Notificaci√≥n de completado
```

### 2. Actualizaci√≥n de Colecciones
```
Cliente ‚Üí Orchestrator ‚Üí Ingestion Service ‚Üí Actualizaci√≥n de metadatos ‚Üí Notificaci√≥n
```

> üîç **Rol del Ingestion Service**: Procesar documentos en diversos formatos, extraer texto estructurado, dividirlo en chunks optimizados para RAG y coordinar la generaci√≥n de embeddings y almacenamiento.

## Arquitectura

El servicio sigue una arquitectura de procesamiento modular:

```
Cliente ‚Üí Ingestion Service ‚Üí Cola de procesamiento
                ‚Üì
           Validaci√≥n
                ‚Üì
      Extracci√≥n de texto
                ‚Üì
      Chunking inteligente
                ‚Üì
      Embedding Service ‚Üê Solicitud de embeddings
                ‚Üì
      Almacenamiento en BD vectorial
                ‚Üì
      Notificaci√≥n de completado
```

### Componentes Principales

- **routes/ingestion.py**: Endpoints principales para carga de documentos
- **routes/documents.py**: Gesti√≥n de documentos existentes
- **routes/collections.py**: Gesti√≥n de colecciones de documentos
- **routes/jobs.py**: Monitoreo de trabajos de procesamiento
- **services/chunking.py**: Procesamiento y divisi√≥n de documentos
- **services/embedding.py**: Cliente del servicio de embeddings
- **services/queue.py**: Sistema de colas para procesamiento as√≠ncrono
- **services/storage.py**: Gesti√≥n de almacenamiento de archivos
- **services/worker.py**: Workers para procesamiento en segundo plano

## üö¶ Sistema de Colas Multi-tenant

### Estructura Jer√°rquica de Colas del Ingestion Service

```
+--------------------------------------------------+
|             COLAS DE INGESTION                   |
+--------------------------------------------------+
|                                                  |
| ingestion_tasks:{tenant_id}                      | ‚Üí Cola principal de tareas
| ingestion_batch:{tenant_id}:{batch_id}           | ‚Üí Lotes de documentos
| ingestion_status:{tenant_id}:{job_id}            | ‚Üí Estado de procesamiento
| ingestion_collection:{tenant_id}:{collection_id} | ‚Üí Metadatos de colecci√≥n 
|                                                  |
+--------------------------------------------------+
```

### Caracter√≠sticas Clave

- **Segmentaci√≥n por tenant**: Completo aislamiento de datos entre tenants
- **Procesamiento por lotes**: Optimizaci√≥n para grandes vol√∫menes de documentos
- **Tracking detallado**: Seguimiento granular del estado de cada documento
- **Reintentos autom√°ticos**: Recuperaci√≥n ante fallos en procesamiento

### Formato de Mensaje Estandarizado

```json
{
  "job_id": "uuid-v4",
  "tenant_id": "tenant-identifier",
  "collection_id": "collection-identifier",
  "created_at": "ISO-timestamp",
  "status": "pending|processing|completed|failed",
  "type": "document_ingestion|metadata_update|collection_management",
  "priority": 0-9,
  "metadata": {
    "source": "upload|url|text|batch",
    "document_type": "pdf|docx|txt|html|...",
    "workflow_id": "optional-workflow-id"
  },
  "payload": {
    "file_path": "path/to/document", 
    "document_id": "optional-document-id",
    "chunking_strategy": "recursive|sentence|paragraph|...",
    "chunk_size": 1000,
    "chunk_overlap": 200
  }
}
```

## Instalaci√≥n

```bash
# Clonar el repositorio
git clone <repositorio>

# Instalar dependencias
cd ingestion-service
pip install -r requirements.txt

# Ejecutar el servicio
python main.py
```

## Configuraci√≥n

El servicio utiliza variables de entorno para su configuraci√≥n:

```bash
# Configuraci√≥n del servicio
SERVICE_NAME=ingestion-service
SERVICE_VERSION=1.0.0
LOG_LEVEL=INFO

# Conexiones externas
SUPABASE_URL=
SUPABASE_KEY=
REDIS_URL=redis://redis:6379/0

# Configuraci√≥n de procesamiento
MAX_WORKERS=4
MAX_QUEUE_SIZE=1000
MAX_DOC_SIZE_MB=20
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200

# URL del servicio de embeddings
EMBEDDING_SERVICE_URL=http://embedding-service:8000
```

## API

### Endpoints Principales

#### Ingesta de Documentos

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/upload` | POST | Carga y procesa un archivo de documento |
| `/ingest/url` | POST | Procesa y extrae contenido de una URL |
| `/ingest/text` | POST | Procesa texto plano como documento |
| `/ingest/batch/urls` | POST | Procesa un lote de URLs en segundo plano |

#### Gesti√≥n de Documentos

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/documents` | GET | Lista documentos por colecci√≥n |
| `/documents/{document_id}` | GET | Obtiene metadatos de un documento |
| `/documents/{document_id}` | DELETE | Elimina un documento |
| `/documents/{document_id}/content` | GET | Obtiene el contenido de un documento |

#### Gesti√≥n de Colecciones

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/collections` | GET | Lista colecciones disponibles |
| `/collections` | POST | Crea una nueva colecci√≥n |
| `/collections/{collection_id}` | GET | Obtiene detalles de una colecci√≥n |
| `/collections/{collection_id}` | DELETE | Elimina una colecci√≥n y sus documentos |

#### Monitoreo de Trabajos

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/jobs/{job_id}` | GET | Obtiene estado de un trabajo de procesamiento |
| `/jobs` | GET | Lista trabajos recientes por tenant |

### Ejemplo de Uso

#### Carga de Documento

```python
import requests

# Datos del documento
files = {"file": open("documento.pdf", "rb")}
data = {
    "collection_id": "mi-coleccion",
    "title": "Mi Documento",
    "description": "Descripci√≥n del documento",
    "tags": "tag1,tag2"
}

# Enviar solicitud
response = requests.post(
    "http://ingestion-service:8000/upload",
    files=files,
    data=data,
    headers={"x-tenant-id": "tenant123"}
)

# Verificar resultado
if response.status_code == 202:
    job_id = response.json().get("job_id")
    print(f"Documento en procesamiento. Job ID: {job_id}")
```

#### Verificar Estado del Trabajo

```python
import requests

job_id = "job_123456"

response = requests.get(
    f"http://ingestion-service:8000/jobs/{job_id}",
    headers={"x-tenant-id": "tenant123"}
)

status = response.json()
print(f"Estado: {status['status']}")
print(f"Progreso: {status['progress']}%")
```

## üîå Sistema de Notificaciones

### WebSockets Centralizados

- **Integraci√≥n con orquestador**: Comunicaci√≥n bidireccional con Agent Orchestrator
- **Notificaciones de progreso**: Actualizaci√≥n en tiempo real del estado de procesamiento
- **Reconexi√≥n autom√°tica**: Mecanismo de backoff exponencial para mayor resiliencia
- **Autenticaci√≥n por token**: Comunicaci√≥n segura entre servicios

### Eventos Espec√≠ficos del Ingestion Service

- `document_ingestion_started`: Inicio del procesamiento de un documento
- `ingestion_progress_update`: Actualizaci√≥n de progreso con porcentaje
- `document_processing_completed`: Documento completamente procesado
- `document_ingestion_failed`: Error en el procesamiento del documento

### Implementaci√≥n WebSocket para Notificaciones:

```python
# websocket/notifier.py
import asyncio
import websockets
import json
import logging
from datetime import datetime

ORCHESTRATOR_WS_URL = "ws://agent-orchestrator:8000/ws/task_updates"

logger = logging.getLogger(__name__)

async def notify_ingestion_progress(job_id, tenant_id, progress_percentage, global_task_id=None):
    """Notifica el progreso de un trabajo de ingesti√≥n"""
    try:
        async with websockets.connect(ORCHESTRATOR_WS_URL) as websocket:
            notification = {
                "event": "ingestion_progress_update",
                "service": "ingestion",
                "task_id": job_id,
                "global_task_id": global_task_id,
                "tenant_id": tenant_id,
                "timestamp": datetime.utcnow().isoformat(),
                "data": {
                    "progress_percentage": progress_percentage,
                    "status": "processing" if progress_percentage < 100 else "completed"
                }
            }
            await websocket.send(json.dumps(notification))
    except Exception as e:
        logger.error(f"Error al notificar progreso via WebSocket: {e}")

async def notify_ingestion_completed(job_id, tenant_id, result, global_task_id=None):
    """Notifica la finalizaci√≥n de un trabajo de ingesti√≥n"""
    try:
        async with websockets.connect(ORCHESTRATOR_WS_URL) as websocket:
            notification = {
                "event": "document_processing_completed",
                "service": "ingestion",
                "task_id": job_id,
                "global_task_id": global_task_id,
                "tenant_id": tenant_id,
                "timestamp": datetime.utcnow().isoformat(),
                "data": result
            }
            await websocket.send(json.dumps(notification))
    except Exception as e:
        logger.error(f"Error al notificar completado via WebSocket: {e}")
```

## üåê Integraci√≥n en el Ecosistema

### Beneficios de la Arquitectura

- **Procesamiento especializado**: Optimizaci√≥n para diferentes tipos de documentos
- **Escalabilidad independiente**: El servicio puede escalarse seg√∫n la demanda de ingesti√≥n
- **Asincron√≠a completa**: Procesamiento en background sin bloquear otras operaciones
- **Flexibilidad en estrategias**: F√°cil adaptaci√≥n a diferentes necesidades de chunking y extracci√≥n

## Mejores Pr√°cticas

### Chunking Optimizado

El servicio implementa estrategias avanzadas de chunking:

1. **Chunking por fragmentos sem√°nticos**: Divide el texto respetando la estructura sem√°ntica
2. **Solapamiento configurable**: Mantiene contexto entre fragmentos
3. **Metadatos enriquecidos**: Incluye informaci√≥n sobre origen, posici√≥n y relaciones

### Procesamiento Eficiente

Para un procesamiento √≥ptimo:

1. **Tama√±o de documentos**: Los documentos no deben exceder el l√≠mite configurado (por defecto 20MB)
2. **Formato de documentos**: Preferir formatos estructurados como PDF, DOCX o HTML
3. **Colecciones**: Organizar documentos en colecciones tem√°ticas para mejor recuperaci√≥n
4. **Metadatos**: Proporcionar metadatos descriptivos (t√≠tulo, tags, descripci√≥n)

### Ingesta por Lotes

Para ingesta masiva:

1. **Endpoint de lotes**: Utilizar `/ingest/batch/urls` para procesar m√∫ltiples URLs
2. **Monitoreo de trabajos**: Verificar el estado mediante el endpoint `/jobs/{job_id}`
3. **Reintentos**: Implementar l√≥gica de reintentos en el cliente para documentos fallidos

## Flujo de Procesamiento

1. **Recepci√≥n**: El documento se recibe a trav√©s de un endpoint
2. **Validaci√≥n**: Se verifica formato, tama√±o y permisos
3. **Encolado**: Se crea un trabajo as√≠ncrono y se encola
4. **Extracci√≥n**: Un worker extrae el texto del documento
5. **Chunking**: El texto se divide en fragmentos √≥ptimos
6. **Embeddings**: Se solicitan embeddings al embedding-service
7. **Almacenamiento**: Los fragmentos con embeddings se almacenan en la base de datos
8. **Notificaci√≥n**: Se actualiza el estado del trabajo a completado

## Resoluci√≥n de Problemas

### Problemas Comunes

| Problema | Posible Causa | Soluci√≥n |
|----------|---------------|----------|
| Error 413 | Documento demasiado grande | Reducir tama√±o o dividir documento |
| Error 415 | Formato no soportado | Convertir a formato soportado (PDF, DOCX) |
| Error 429 | L√≠mite de rate excedido | Implementar backoff exponencial |
| Error 500 en extracci√≥n | Documento da√±ado o protegido | Verificar integridad y permisos |
| Timeout en procesamiento | Documento muy complejo | Aumentar timeout o dividir documento |

### Logs y Monitoreo

El servicio emite logs detallados sobre el proceso de ingesta:

- **INFO**: Eventos normales de procesamiento
- **WARNING**: Problemas no cr√≠ticos (reintentos, degradaci√≥n)
- **ERROR**: Fallos en procesamiento, conexiones o almacenamiento

## Integraci√≥n con Otros Servicios

- **Embedding Service**: Para generaci√≥n de embeddings
- **Query Service**: Utiliza los documentos procesados para responder consultas
- **Agent Service**: Orquesta el proceso completo de RAG

## Seguridad

- **Validaci√≥n de tenant**: Todos los endpoints requieren un tenant v√°lido
- **Sanitizaci√≥n de contenido**: Limpieza de contenido malicioso
- **L√≠mites por tier**: Restricciones seg√∫n el plan del tenant
- **Aislamiento de datos**: Estricta separaci√≥n entre tenants
