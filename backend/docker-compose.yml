version: '3.8'

services:
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    healthcheck:
      disable: true  # deshabilitado por problemas de disponibilidad intermitente
    restart: always

  embedding-service:
    build:
      context: .
      dockerfile: docker/services/Dockerfile.embedding
    restart: always
    ports:
      - "8001:8001"
    volumes:
      - ./common:/app/common
      - ./embedding-service:/app/embedding-service
    dns:
      - 8.8.8.8
      - 1.1.1.1
    environment:
      # Variables de credenciales
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SUPABASE_URL=${SUPABASE_URL:-https://example.supabase.co}
      - SUPABASE_KEY=${SUPABASE_KEY:-dummy-key-for-testing}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY:-dummy-service-key-for-testing}
      
      # Variables de identificación del servicio
      - SERVICE_NAME=embedding-service
      
      # Variables de conexión con servicios
      - REDIS_URL=redis://redis:6379/0
      - OLLAMA_API_URL=http://ollama:11434
      
      # Variables de configuración multi-tenant
      - TENANT_ID=default
      - CONFIG_ENVIRONMENT=development
      - LOAD_CONFIG_FROM_SUPABASE=false
      
      # Variables de configuración general
      - LOG_LEVEL=INFO
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - DEFAULT_OLLAMA_EMBEDDING_MODEL=${DEFAULT_OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - DEFAULT_OLLAMA_LLM_MODEL=${DEFAULT_OLLAMA_LLM_MODEL:-llama3:1b}
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_started

  query-service:
    build:
      context: .
      dockerfile: docker/services/Dockerfile.query
    restart: always
    ports:
      - "8002:8002"
    volumes:
      - ./common:/app/common
      - ./query-service:/app/query-service
    dns:
      - 8.8.8.8
      - 1.1.1.1
    environment:
      # Variables de credenciales
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SUPABASE_URL=${SUPABASE_URL:-https://example.supabase.co}
      - SUPABASE_KEY=${SUPABASE_KEY:-dummy-key-for-testing}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY:-dummy-service-key-for-testing}
      
      # Variables de identificación del servicio
      - SERVICE_NAME=query-service
      
      # Variables de conexión con servicios
      - REDIS_URL=redis://redis:6379/0
      - EMBEDDING_SERVICE_URL=http://embedding-service:8001
      - OLLAMA_API_URL=http://ollama:11434
      
      # Variables de configuración multi-tenant
      - TENANT_ID=default
      - CONFIG_ENVIRONMENT=development
      - LOAD_CONFIG_FROM_SUPABASE=false
      
      # Variables de configuración general
      - LOG_LEVEL=INFO
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - DEFAULT_OLLAMA_EMBEDDING_MODEL=${DEFAULT_OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - DEFAULT_OLLAMA_LLM_MODEL=${DEFAULT_OLLAMA_LLM_MODEL:-llama3:1b}
    depends_on:
      redis:
        condition: service_healthy
      embedding-service:
        condition: service_started
      ollama:
        condition: service_started

  agent-service:
    build:
      context: .
      dockerfile: docker/services/Dockerfile.agent
    restart: always
    ports:
      - "8003:8003"
    volumes:
      - ./common:/app/common
      - ./agent-service:/app/agent-service
    dns:
      - 8.8.8.8
      - 1.1.1.1
    environment:
      # Variables de credenciales
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SUPABASE_URL=${SUPABASE_URL:-https://example.supabase.co}
      - SUPABASE_KEY=${SUPABASE_KEY:-dummy-key-for-testing}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY:-dummy-service-key-for-testing}
      
      # Variables de identificación del servicio
      - SERVICE_NAME=agent-service
      
      # Variables de conexión con servicios
      - REDIS_URL=redis://redis:6379/0
      - EMBEDDING_SERVICE_URL=http://embedding-service:8001
      - QUERY_SERVICE_URL=http://query-service:8002
      - OLLAMA_API_URL=http://ollama:11434
      
      # Variables de configuración multi-tenant
      - TENANT_ID=default
      - CONFIG_ENVIRONMENT=development
      - LOAD_CONFIG_FROM_SUPABASE=false
      
      # Variables de configuración general
      - LOG_LEVEL=INFO
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - DEFAULT_OLLAMA_EMBEDDING_MODEL=${DEFAULT_OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - DEFAULT_OLLAMA_LLM_MODEL=${DEFAULT_OLLAMA_LLM_MODEL:-llama3:1b}
      - JOB_LOCK_EXPIRE_SECONDS=600
    depends_on:
      redis:
        condition: service_healthy
      embedding-service:
        condition: service_started
      query-service:
        condition: service_started
      ollama:
        condition: service_started

  ingestion-service:
    build:
      context: .
      dockerfile: docker/services/Dockerfile.ingestion
    restart: always
    ports:
      - "8000:8000"
    volumes:
      - ./common:/app/common
      - ./ingestion-service:/app/ingestion-service
    dns:
      - 8.8.8.8
      - 1.1.1.1
    environment:
      # Variables de credenciales
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SUPABASE_URL=${SUPABASE_URL:-https://example.supabase.co}
      - SUPABASE_KEY=${SUPABASE_KEY:-dummy-key-for-testing}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY:-dummy-service-key-for-testing}
      
      # Variables de identificación del servicio
      - SERVICE_NAME=ingestion-service
      
      # Variables de conexión con servicios
      - REDIS_URL=redis://redis:6379/0
      - EMBEDDING_SERVICE_URL=http://embedding-service:8001
      - QUERY_SERVICE_URL=http://query-service:8002
      - OLLAMA_API_URL=http://ollama:11434
      - JOB_LOCK_EXPIRE_SECONDS=600
      
      # Variables de configuración multi-tenant
      - TENANT_ID=default
      - CONFIG_ENVIRONMENT=development
      - LOAD_CONFIG_FROM_SUPABASE=false
      
      # Variables de configuración general
      - LOG_LEVEL=INFO
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - DEFAULT_OLLAMA_EMBEDDING_MODEL=${DEFAULT_OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - DEFAULT_OLLAMA_LLM_MODEL=${DEFAULT_OLLAMA_LLM_MODEL:-llama3:1b}
    depends_on:
      redis:
        condition: service_healthy
      embedding-service:
        condition: service_started
      ollama:
        condition: service_started

volumes:
  redis-data:
  ollama-data: